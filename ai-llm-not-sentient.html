<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>No, Todays AI Isnt Sentient. Heres How We Know - ByteBlog</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="Artificial general intelligence (AGI) is the term used to describe an artificial agent that is at least as intelligent as a human in all the many ways a human displays (or can display) intelligence. Its what we used to call artificial intelligence, until we started creating programs and devices that were undeniably intelligent, but in"><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="No, Todays AI Isnt Sentient. Heres How We Know"><meta property="og:description" content="Artificial general intelligence (AGI) is the term used to describe an artificial agent that is at least as intelligent as a human in all the many ways a human displays (or can display) intelligence. Its what we used to call artificial intelligence, until we started creating programs and devices that were undeniably intelligent, but in"><meta property="og:type" content="article"><meta property="og:url" content="/ai-llm-not-sentient.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-07-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-05T00:00:00+00:00"><meta itemprop=name content="No, Todays AI Isnt Sentient. Heres How We Know"><meta itemprop=description content="Artificial general intelligence (AGI) is the term used to describe an artificial agent that is at least as intelligent as a human in all the many ways a human displays (or can display) intelligence. Its what we used to call artificial intelligence, until we started creating programs and devices that were undeniably intelligent, but in"><meta itemprop=datePublished content="2024-07-05T00:00:00+00:00"><meta itemprop=dateModified content="2024-07-05T00:00:00+00:00"><meta itemprop=wordCount content="1351"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=ByteBlog rel=home><div class="logo__item logo__text"><div class=logo__title>ByteBlog</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>No, Todays AI Isnt Sentient. Heres How We Know</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-07-05T00:00:00Z>July 05, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><img src=https://cdn.statically.io/img/api.time.com/wp-content/uploads/2024/05/sentient-ai-llm.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p><span role=presentation class=dropcap>A</span>rtificial general intelligence (AGI) is the term used to describe an artificial agent that is at least as intelligent as a human in all the many ways a human displays (or can display) intelligence. It’s what we used to call artificial intelligence, until we started creating programs and devices that were undeniably “intelligent,” but in limited domains—playing chess, translating language, vacuuming our living rooms.</p><p>The felt need to add the “G” came from the proliferation of systems powered by AI, but focused on a single or very small number of tasks. Deep Blue, IBM’s impressive early chess playing program, could beat world champion Garry Kasparov, but would not have the sense to stop playing if the room burst into flames.</p><p>Now, general intelligence is a bit of a myth, at least if we flatter ourselves that we have it. We can find plenty of examples of intelligent behavior in the animal world that achieve results far better than we could achieve on similar tasks. Our intelligence is not fully general, but general enough to get done what we want to get done in most environments we find ourselves in. If we’re hungry, we can hunt a mastodon or find a local Kroger’s; when the room catches on fire, we look for the exit.</p><p>One of the essential characteristics of general intelligence is “sentience,” the ability to have <i>subjective experiences</i>—to feel what it’s like, say, to experience hunger, to taste an apple, or to see red. Sentience is a crucial step on the road to general intelligence.</p><p>With the release of ChatGPT in November 2022, the era of large language models (LLMs) began. This instantly sparked a vigorous debate about whether these algorithms might in fact be sentient. The implications of the possible sentience of LLM-based AI has not only set off a media frenzy, but also profoundly impacted some of the world-wide policy efforts to regulate AI. The most prominent position is that the emergence of “sentient AI” could be extremely dangerous for human-kind, possibly bringing about an “extinction-level” or “existential” crisis. After all, a sentient AI might develop its own hopes and desires, with no guarantee they wouldn’t clash with ours.</p><p>This short piece started as a WhatsApp group chat to debunk the argument that LLMs might have achieved sentience. It is not meant to be complete or comprehensive. Our main point here is to argue against the most common defense offered by the “sentient AI” camp, which rests on LLMs’ ability to report having “subjective experiences.”</p><h2>Why some people believe AI has achieved sentience</h2><p>Over the past months, both of us have had robust debates and conversations with many colleagues in the field of AI, including some deep one-on-one conversations with some of the most prominent and pioneering AI scientists. The topic of whether AI has achieved sentience has been a prominent one. A small number of them believe strongly that it has. Here is the gist of their arguments by one of the most vocal proponents, quite representative of those in the “sentient AI” camp:</p><figure class=blockquote role=presentation readability=12><p>“AI is sentient because it reports subjective experience. Subjective experience is the hallmark of consciousness. It is characterized by the claim of knowing what you know or experience. I believe that you, as a person, are conscious when you say ‘I have the subjective experience of feeling happy after a good meal.’ I, as a person, actually have no direct evidence of <i>your</i> subjective experience. But since you communicated that, I take it at face value that indeed you have the subjective experience and so are conscious.</p><p>“Now, let’s apply the same ‘rule’ to LLMs. Just like any human, I don’t have access to an LLM’s internal states. But I can query its subjective experiences. I can ask ‘are you feeling hungry?’ It can actually tell me yes or no. Furthermore, it can also explicitly share with me its ‘subjective experiences,’ on almost anything, from seeing the color red, being happy after a meal, to having strong political views. Therefore, I have no reason to believe it’s not conscious or not aware of its own subjective experiences, just like I have no reason to believe that you are not conscious. My evidence is exactly the same in both cases.”</p></figure><h2>Why they’re wrong</h2><p>While this sounds plausible at first glance, the argument is wrong. It is wrong because our evidence is not exactly the same in both cases. Not even close.</p><p>When I conclude that you are experiencing hunger when you say “I’m hungry,” my conclusion is based on a large cluster of circumstances. First, is your report—the words that you speak—and perhaps some other behavioral evidence, like the grumbling in your stomach. Second, is the absence of contravening evidence, as there might be if you had just finished a five-course meal. Finally, and this is most important, is the fact that you have a physical body like mine, one that periodically needs food and drink, that gets cold when it’s cold and hot when it’s hot, and so forth.</p><p>Now compare this to our evidence about an LLM. The only thing that is common is the report, the fact that the LLM can produce the string of syllables “I’m hungry.” But there the similarity ends. Indeed, the LLM doesn’t have a body and <i>so is not even the kind of thing that can be hungry.</i></p><p>If the LLM were to say, “I have a sharp pain in my left big toe,” would we conclude that it had a sharp pain in its left big toe? Of course not, it doesn’t have a left big toe! Just so, when it says that it is hungry, we can in fact be certain that it is not, <i>since it doesn’t have the kind of physiology required for hunger.</i></p><p>When humans experience hunger, they are sensing a collection of physiological states—low blood sugar, empty grumbling stomach, and so forth—that an LLM simply doesn’t have, any more than it has a mouth to put food in and a stomach to digest it. The idea that we should take it at its word when it says it is hungry is like saying we should take it at its word if it says it’s speaking to us from the dark side of the moon. We know it’s not, and the LLM’s assertion to the contrary does not change that fact.</p><p>All sensations—hunger, feeling pain, seeing red, falling in love—are the result of physiological states that an LLM simply doesn’t have. Consequently we know that an LLM cannot have subjective experiences of those states. In other words, it cannot be sentient.</p><p>An LLM is a mathematical model coded on silicon chips. It is not an embodied being like humans. It does not have a “life” that needs to eat, drink, reproduce, experience emotion, get sick, and eventually die.</p><p>It is important to understand the profound difference between how humans generate sequences of words and how an LLM generates those same sequences. When I say “I am hungry,” I am reporting on my sensed physiological states. When an LLM generates the sequence “I am hungry,” it is simply generating the most probable completion of the sequence of words in its current prompt. It is doing exactly the same thing as when, with a different prompt, it generates “I am <i>not</i> hungry,” or with yet another prompt, “The moon is made of green cheese.” None of these are reports of its (nonexistent) physiological states. They are simply probabilistic completions.</p><p>We have not achieved sentient AI, and larger language models won’t get us there. We need a better understanding of how sentience emerges in embodied, biological systems if we want to recreate this phenomenon in AI systems. We are not going to stumble on sentience with the next iteration of ChatGPT.</p><p>Li and Etchemendy are co-founders of the Institute for Human-Centered Artificial Intelligence at Stanford University. Li is a professor of Computer Science, author of ‘The Worlds I See,’ and 2023 <a href=#>TIME100 AI</a> honoree. Etchemendy is a professor of Philosophy and former provost of Stanford.</p><p>More Must-Reads from TIME</p><p class=author-feedback-text><strong>Contact us</strong> at <a href=# rel="noopener noreferrer">letters@time.com</a>.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmismaKyb6%2FOpmacp5yhsqTAyKilaKyZorJyfI9mraihk5rAcIKYcWdqa2Rkrqp5y6WkZqafqXq0sc2toJ6mpGQ%3D</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./ruger-previews-new-song-off-upcoming-album.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Ruger previews new song off upcoming album</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./melting-away-stunning-photos-of-disappearing-icebergs.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Melting Away: A Photographer's Journey to Preserve the Polar Regions</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./aliens-abducted-my-parents-and-now-i-feel-kinda-left-out-trailer-jake-van-wagoners-exclusive-1235496708.html>Emma Tremblay Discovers an Out-of-this-World Secret in Aliens Abducted My Parents and Now I</a></li><li class=widget__item><a class=widget__link href=./how-much-money-does-bret-michaels-make-html.html>How Much Money Does Bret Michaels Make? Latest Income Salary</a></li><li class=widget__item><a class=widget__link href=./what-the-celebrity-phenomenon-is-and-why-people-are-getting-famous-for-seemingly-nothing-803349.html>How People Get Famous for Seemingly Nothing and Why People Obsess Over Them</a></li><li class=widget__item><a class=widget__link href=./1550742-n5bn-palliative-states-nigerians-hold-accountable-tinubu.html>N5bn Palliative to States: Nigerians Must Hold Govs Accountable, Tinubu</a></li><li class=widget__item><a class=widget__link href=./pirates-pic-unbuckled-1117929120.html>Pirates pic unbuckled</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 ByteBlog.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>